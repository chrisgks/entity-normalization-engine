from flair.models import SequenceTagger
from flair.embeddings import WordEmbeddings
from flair.embeddings import CharacterEmbeddings
from flair.embeddings import FlairEmbeddings
from flair.embeddings import TransformerWordEmbeddings
from flair.embeddings import DocumentPoolEmbeddings
from flair.data import Sentence

# Flair library supports compination of various word embeddings generated by various base models
# constructing all the models once and not loading a new one at every function call; saves a lot of ram; faster
# we have acces to all the transformers present in the 'hugging face' library
bert_embedding = TransformerWordEmbeddings('bert-base-cased')
roberta_embedding = TransformerWordEmbeddings('roberta-base')
glove_embedding = WordEmbeddings('glove')
character_embeddings = CharacterEmbeddings()
flair_forward = FlairEmbeddings('news-forward-fast')
flair_backward = FlairEmbeddings('news-backward-fast')


def vectorize(string: str = None, selected_base_models: list = None):
    # 'vectorizes' the input string using one or a combination of word embeddings - if 'vector representation'
    # is being selected at Algorithms construction time.
    """
    :param string, input string
    :param selected_base_models list of the models we want to use in order to create word embeddings
    :return: embedding
    """

    if not selected_base_models:
        raise SystemExit(f"[ERROR]: function {vectorize.__name__}() -> Provide at least one base model: ['bert',"
                         f"'roberta', 'glove', 'character', 'flair_forward', 'flair_backward']")

    embeddings = []

    if 'bert' in selected_base_models:
        embeddings.append(bert_embedding)
    if 'roberta' in selected_base_models:
        embeddings.append(roberta_embedding)
    if 'glove' in selected_base_models:
        embeddings.append(glove_embedding)
    if 'character' in selected_base_models:
        embeddings.append(character_embeddings)
    if 'flair_forward' in selected_base_models:
        embeddings.append(flair_forward)
    if 'flair_backward' in selected_base_models:
        embeddings.append(flair_backward)

    # if none of the above, then the model combination passed is not supported
    if not embeddings:
        raise SystemExit(f"[ERROR]: function {vectorize.__name__}() -> {selected_base_models} not available. "
                         f"Supported models: "
                         f"['bert', 'roberta', 'glove', 'character', 'flair_forward', 'flair_backward']")

    # we are making use of Flair's API, DocumentPoolEmbeddings takes a list of embeddings to be combined
    # for a string containing whitespaces, it creates word embeddings for each word and then combines them. 'pooling'
    # parameter controls the way they are combined - We've chosen to combine them by taking their mean value
    stacked_embeddings = DocumentPoolEmbeddings(embeddings=embeddings,
                                                fine_tune_mode='none',
                                                pooling='mean')

    sentence = Sentence(string)

    # combination by concatenating each models' output (stackin) - thanks Flair API :)
    stacked_embeddings.embed(sentence)

    # detach() because if fine_tune_mode is set to, for exapme: 'linear', or 'non-linear', apart from the embedding
    # itself, it also returns the computed gradients of each layer (Pytorch's Autograd module - It records all the
    # perations that we are performing and replays it backward to compute gradients.)
    # we could tweak fine_tune_mode if wanted to fine tune the bese model further by training on external data sets
    return sentence.embedding.detach().numpy()


# loading the NER tagger once and not loading a new one at every function call; saves some ram; faster
tagger = SequenceTagger.load('ner')


def entity_recognition(input_string: str):
    """
    Classifies strings into one of three classes (company name, locations, unknown_soup).
    :param input_string, string to be classified
    :return: entity id
    """
    instance = Sentence(input_string)
    tagger.predict(instance)
    to_string = instance.to_tagged_string()

    if "ORG" in to_string:
        return 1
    # if its a location then it most likely do not have a number in the name - an attempt to reduce classification error
    elif "LOC" in to_string and not has_digit(input_string):
        return 2
    else:
        # corresponds to 'unknown_soup' entity
        return 3


def has_digit(string: str):
    """
    Checks if "Locations" entity has any digits - an attempt to minimize NER's errors
    :param string: entity name
    :return: bool
    """
    return any(char.isdigit() for char in string)
